defaults:
  - model: xgboost
  - hpo: tpe
  - _self_

seed: 42

mlflow:
  tracking_uri: "http://127.0.0.1:5000"
  experiment_name: "creditcard-fraud-hpo"
  log_model: true
  register_model: false
  model_name: "BestOptimizedModel"
  stage: "Staging"

data:
  train_path: "data/prepared/train.csv"
  test_path: "data/prepared/test.csv"
  target_col: "Class"
  val_size: 0.2

model:
  type: "xgboost"

hpo:
  n_trials: 20
  n_trials_per_model: 50
  run_all_models: false
  sampler: "tpe"
  metric: "auprc"
  direction: "maximize"
  use_cv: false
  cv_folds: 5

  # XGBoost search space
  xgboost:
    n_estimators: { low: 50, high: 300 }
    max_depth: { low: 3, high: 15 }
    learning_rate: { low: 0.001, high: 0.3 }  # log scale
    subsample: { low: 0.6, high: 1.0 }
    colsample_bytree: { low: 0.6, high: 1.0 }
    reg_alpha: { low: 0.00001, high: 10 }   # log scale
    reg_lambda: { low: 0.00001, high: 10 } # log scale
    min_child_weight: { low: 1, high: 10 }

  # Random Forest search space
  random_forest:
    n_estimators: { low: 50, high: 300 }
    max_depth: { low: 3, high: 20 }
    min_samples_split: { low: 2, high: 20 }
    min_samples_leaf: { low: 1, high: 10 }

  # LightGBM search space (звужений)
  lightgbm:
    n_estimators: { low: 50, high: 300 }
    max_depth: { low: 3, high: 15 }
    learning_rate: { low: 0.001, high: 0.2 }  # log scale
    num_leaves: { low: 31, high: 128 }
    subsample: { low: 0.6, high: 1.0 }
    reg_alpha: { low: 0.00001, high: 10 }  # log scale

hydra:
  run:
    dir: .
  output_subdir: null
