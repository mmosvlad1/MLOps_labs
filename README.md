# Лабораторна робота №1. Організація робочого простору MLOps інженера та автоматизація відстеження експериментів

## 1. Мета роботи

1. Опанувати навички налаштування професійного ізольованого середовища розробки для Data Science проєктів.
2. Засвоїти принципи структурування ML-проєктів згідно зі стандартами індустрії (Cookiecutter Data Science).
3. Навчитися використовувати інструменти контролю версій (Git) з урахуванням специфіки ML-проєктів (ігнорування даних, артефактів).
4. Реалізувати автоматизоване відстеження експериментів (Experiment Tracking) за допомогою платформи MLflow.
5. Провести первинний аналіз даних (EDA) та побудувати базову модель (Baseline) для обраного датасету.

## 2. Виконані завдання

1. ✅ Налаштовано локальне середовище розробки: Python, Git, віртуальне середовище.
2. ✅ Ініціалізовано Git-репозиторій та налаштовано `.gitignore`.
3. ✅ Обрано датасет Credit Card Fraud Detection та завантажено його у директорію проєкту.
4. ✅ Створено Jupyter Notebook для первинного аналізу даних (EDA).
5. ✅ Розроблено Python-скрипт `train.py` для тренування моделі: завантаження даних, передобробка та навчання.
6. ✅ Інтегровано MLflow для логування гіперпараметрів, метрик якості (train_auprc, val_auprc) та артефактів моделі (confusion matrix, feature importance).
7. ✅ Виконано 8 експериментів з різними значеннями гіперпараметра `n_estimators`.

## 3. Датасет

**Credit Card Fraud Detection** — датасет транзакцій з позначкою фродових операцій. Містить анонімізовані ознаки (V1–V28), час транзакції, суму та цільову змінну Class (0 — нормальна транзакція, 1 — фрод).

## 4. Експерименти

Проведено 8 експериментів із моделлю **XGBoost**. Змінний гіперпараметр: `n_estimators` = {2, 5, 10, 20, 50, 70, 100, 200}. Фіксовані параметри: `max_depth` = 10, `learning_rate` = 0.1.

Метрика якості: **AUPRC** (Area Under the Precision-Recall Curve) — доцільна для сильно збалансованих даних (фродових випадків мало).

## 5. MLflow

- Створено експеримент **creditcard-fraud** з власною назвою.
- Відображається список запусків (Runs) з метриками та тегами.
- Використано функцію **Compare**: виділено всі 8 запусків та побудовано візуалізацію залежності метрик від гіперпараметра `n_estimators`.

### Скріншот списку експериментів

![Список Runs у MLflow](mlops_lab_1/images/mlflow_experiments.png)

*Скріншот MLflow UI: створений експеримент creditcard-fraud та список запусків (Runs) з метриками train_auprc, val_auprc та тегом n_estimators.*

### Скріншот порівняння (Compare)

![Порівняння Runs у MLflow](mlops_lab_1/images/mlflow_compare.png)

*Скріншот функції Compare: Parallel Coordinates Plot — залежність train_auprc та val_auprc від n_estimators.*

## 6. Аналіз результатів

**Залежність train_auprc від n_estimators:** При збільшенні кількості дерев train_auprc монотонно зростає і досягає ~1.0 при n_estimators ≥ 70. Модель дуже добре підлаштовується під тренувальні дані.

**Залежність val_auprc від n_estimators:** val_auprc також зростає з n_estimators, але значно повільніше. При малих значеннях (2, 5) метрика низька (~0.66–0.82), далі виходить на плато ~0.85 при n_estimators від 50 до 200. Найкращий результат val_auprc ≈ 0.857 досягнуто при n_estimators = 200.

**Висновок щодо оверфіту:** Різниця між train_auprc ≈ 1.0 та val_auprc ≈ 0.85 при великих n_estimators вказує на оверфітинг. Для production можна обрати n_estimators ≈ 50–100 як компроміс між якістю та узагальнювальною здатністю.

## 7. Висновки

У межах лабораторної роботи налаштовано ізольоване середовище розробки, структуровано проєкт згідно зі стандартами індустрії та інтегровано MLflow для відстеження експериментів. Реалізовано тренувальний пайплайн для датасету Credit Card Fraud Detection з використанням XGBoost. Проведено 8 експериментів із варіацією n_estimators; аналіз метрик train_auprc та val_auprc дозволив виявити ефект оверфіту при великій кількості дерев. MLflow забезпечує зручне порівняння запусків, логування параметрів та артефактів, що значно спрощує ітеративну розробку ML-моделей.
